#!/usr/bin/env python3
"""
DSL ì…ë ¥ë¶€í„° ì‹¤í–‰ ê³„íš ìƒì„± ë° SPARQL ì¿¼ë¦¬ ì‹¤í–‰ê¹Œì§€
í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬: pip install rdflib
í•„ìš” íŒŒì¼: 
  - execution-ontology.ttl
  - domain-ontology.ttl  
  - bridge-ontology.ttl
  - aas-test-data/sparql-data/*.ttl
"""

from rdflib import Graph, Namespace, URIRef, Literal, RDF, RDFS, OWL, XSD
import json
from datetime import datetime
from typing import Dict, List, Any, Optional
import os

class OntologyBasedExecutionPlannerWithSPARQL:
    def __init__(self, 
                 exec_ttl: str = "execution-ontology.ttl",
                 domain_ttl: str = "domain-ontology.ttl", 
                 bridge_ttl: str = "bridge-ontology.ttl",
                 test_data_dir: str = "aas-test-data/sparql-data"):
        
        # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ì •ì˜
        self.EXEC = Namespace("http://example.org/execution-ontology#")
        self.PROD = Namespace("http://example.org/production-domain#")
        self.BRIDGE = Namespace("http://example.org/bridge-ontology#")
        
        # 3ê°œì˜ ì˜¨í†¨ë¡œì§€ ê·¸ë˜í”„ ì´ˆê¸°í™”
        self.exec_graph = Graph()
        self.domain_graph = Graph()
        self.bridge_graph = Graph()
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¥¼ ìœ„í•œ í†µí•© ê·¸ë˜í”„
        self.data_graph = Graph()
        
        # ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë°”ì¸ë”©
        self._bind_namespaces()
        
        # ì‹¤í–‰ íŒŒì¼ì˜ ë””ë ‰í† ë¦¬ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        self.base_dir = os.path.dirname(os.path.abspath(__file__))
        
        # TTL íŒŒì¼ ê²½ë¡œë¥¼ ì‹¤í–‰ íŒŒì¼ ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •
        self.exec_ttl = os.path.join(self.base_dir, exec_ttl)
        self.domain_ttl = os.path.join(self.base_dir, domain_ttl)
        self.bridge_ttl = os.path.join(self.base_dir, bridge_ttl)
        self.test_data_dir = os.path.join(self.base_dir, test_data_dir)
        
        # ì˜¨í†¨ë¡œì§€ ë¡œë“œ
        self._load_ontologies()
        self._load_action_metadata()
        
        # AAS í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        self._load_aas_test_data()
        
        # ë¸Œë¦¬ì§€ ì˜¨í†¨ë¡œì§€ ë‚´ìš© í™•ì¸ (ë””ë²„ê¹…ìš©)
        self._debug_bridge_ontology()
        
        # SPARQL ì¿¼ë¦¬ ê²°ê³¼ ì €ì¥ì†Œ
        self.sparql_results = {}
        
    def _bind_namespaces(self):
        """ë„¤ì„ìŠ¤í˜ì´ìŠ¤ ë°”ì¸ë”©"""
        for graph in [self.exec_graph, self.domain_graph, self.bridge_graph, self.data_graph]:
            graph.bind("exec", self.EXEC)
            graph.bind("prod", self.PROD)
            graph.bind("bridge", self.BRIDGE)
            graph.bind("rdf", RDF)
            graph.bind("rdfs", RDFS)
            graph.bind("owl", OWL)
            graph.bind("xsd", XSD)
    
    def _load_ontologies(self):
        """3ê°œì˜ ì˜¨í†¨ë¡œì§€ TTL íŒŒì¼ ë¡œë“œ"""
        print("ğŸ“š ì˜¨í†¨ë¡œì§€ TTL íŒŒì¼ ë¡œë“œ ì¤‘...")
        print(f"   ê¸°ì¤€ ë””ë ‰í† ë¦¬: {self.base_dir}")
        
        # ì‹¤í–‰ ì˜¨í†¨ë¡œì§€ ë¡œë“œ
        try:
            self.exec_graph.parse(self.exec_ttl, format="turtle")
            print(f"âœ… ì‹¤í–‰ ì˜¨í†¨ë¡œì§€ ë¡œë“œ ì„±ê³µ: {os.path.basename(self.exec_ttl)}")
            print(f"   - {len(self.exec_graph)} íŠ¸ë¦¬í”Œ")
        except Exception as e:
            print(f"âŒ ì‹¤í–‰ ì˜¨í†¨ë¡œì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
        
        # ë„ë©”ì¸ ì˜¨í†¨ë¡œì§€ ë¡œë“œ
        try:
            self.domain_graph.parse(self.domain_ttl, format="turtle")
            print(f"âœ… ë„ë©”ì¸ ì˜¨í†¨ë¡œì§€ ë¡œë“œ ì„±ê³µ: {os.path.basename(self.domain_ttl)}")
            print(f"   - {len(self.domain_graph)} íŠ¸ë¦¬í”Œ")
        except Exception as e:
            print(f"âŒ ë„ë©”ì¸ ì˜¨í†¨ë¡œì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
        
        # ë¸Œë¦¬ì§€ ì˜¨í†¨ë¡œì§€ ë¡œë“œ
        try:
            self.bridge_graph.parse(self.bridge_ttl, format="turtle")
            print(f"âœ… ë¸Œë¦¬ì§€ ì˜¨í†¨ë¡œì§€ ë¡œë“œ ì„±ê³µ: {os.path.basename(self.bridge_ttl)}")
            print(f"   - {len(self.bridge_graph)} íŠ¸ë¦¬í”Œ")
        except Exception as e:
            print(f"âŒ ë¸Œë¦¬ì§€ ì˜¨í†¨ë¡œì§€ ë¡œë“œ ì‹¤íŒ¨: {e}")
            raise
        
        print()
        
    def _load_aas_test_data(self):
        """AAS í…ŒìŠ¤íŠ¸ ë°ì´í„° TTL íŒŒì¼ë“¤ ë¡œë“œ"""
        print("ğŸ“Š AAS í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ ì¤‘...")
        
        # ë¡œë“œí•  ë°ì´í„° íŒŒì¼ë“¤
        data_files = [
            "static/machines-static.ttl",
            "static/products-static.ttl",
            "static/products-additional.ttl",  # ì¶”ê°€ ì œí’ˆ ë°ì´í„°
            "snapshot/operational-snapshot-20250717.ttl",
            "historical/job-history-20250717.ttl",
            "historical/job-history-20250718.ttl"  # ì¶”ê°€ ë‚ ì§œ ë°ì´í„°
        ]
        
        total_triples = 0
        for file_path in data_files:
            full_path = os.path.join(self.test_data_dir, file_path)
            try:
                before_count = len(self.data_graph)
                self.data_graph.parse(full_path, format="turtle")
                after_count = len(self.data_graph)
                added = after_count - before_count
                total_triples += added
                print(f"âœ… {file_path}: {added} íŠ¸ë¦¬í”Œ ì¶”ê°€")
            except Exception as e:
                print(f"âŒ {file_path} ë¡œë“œ ì‹¤íŒ¨: {e}")
                
        print(f"ğŸ“Š ì´ {total_triples} íŠ¸ë¦¬í”Œ ë¡œë“œ ì™„ë£Œ")
        print()
        
    def _debug_bridge_ontology(self):
        """ë¸Œë¦¬ì§€ ì˜¨í†¨ë¡œì§€ ë‚´ìš© í™•ì¸"""
        print("ğŸ” ë¸Œë¦¬ì§€ ì˜¨í†¨ë¡œì§€ ë””ë²„ê¹…...")
        
        # ëª¨ë“  ë¸Œë¦¬ì§€ ëª©í‘œ í™•ì¸
        query = """
        SELECT ?bridgeGoal ?dslGoal ?execGoal WHERE {
            ?bridgeGoal bridge:mapsGoal ?dslGoal ;
                        bridge:toExecutionGoal ?execGoal .
        }
        """
        
        results = self.bridge_graph.query(query)
        print(f"ë¸Œë¦¬ì§€ ë§¤í•‘ ê°œìˆ˜: {len(list(results))}")
        
        results = self.bridge_graph.query(query)  # ë‹¤ì‹œ ì‹¤í–‰ (iteratorê°€ ì†Œëª¨ë¨)
        for row in results:
            print(f"  - DSL Goal: {row.dslGoal} â†’ Exec Goal: {str(row.execGoal).split('#')[-1]}")
        print()
        
    def _load_action_metadata(self):
        """ì•¡ì…˜ ë©”íƒ€ë°ì´í„° ë¡œë“œ"""
        self.action_metadata = {}
        
        # ì•¡ì…˜ë³„ ë©”íƒ€ë°ì´í„° ì¿¼ë¦¬
        query = """
        PREFIX exec: <http://example.org/execution-ontology#>
        PREFIX rdf: <http://www.w3.org/1999/02/22-rdf-syntax-ns#>
        
        SELECT ?action ?actionType ?queryTemplate ?enrichmentType ?modelEndpoint
        WHERE {
            ?action rdf:type ?actionClass .
            FILTER(?actionClass IN (exec:QueryBuilder, exec:DataEnricher, exec:ServiceCaller, exec:DataTransform, exec:Action))
            OPTIONAL { ?action exec:actionType ?actionType }
            OPTIONAL { ?action exec:hasQueryTemplate ?queryTemplate }
            OPTIONAL { ?action exec:hasEnrichmentType ?enrichmentType }
            OPTIONAL { ?action exec:usesModel/exec:hasEndpoint ?modelEndpoint }
        }
        """
        
        results = self.exec_graph.query(query)
        print(f"\nğŸ“‹ ì•¡ì…˜ ë©”íƒ€ë°ì´í„° ë¡œë“œ: {len(list(results))}ê°œ ì•¡ì…˜")
        
        results = self.exec_graph.query(query)  # ë‹¤ì‹œ ì‹¤í–‰
        for row in results:
            action_uri = str(row.action)
            action_name = action_uri.split('#')[-1]
            
            # actionType ê²°ì •
            action_type = None
            if row.actionType:
                action_type = str(row.actionType).split('#')[-1]
            elif row.queryTemplate:
                action_type = "QueryAction"
            elif row.enrichmentType:
                action_type = "EnrichmentAction"
            elif row.modelEndpoint:
                action_type = "ServiceAction"
            
            self.action_metadata[action_uri] = {
                'actionType': action_type,
                'queryTemplate': str(row.queryTemplate) if row.queryTemplate else None,
                'enrichmentType': str(row.enrichmentType) if row.enrichmentType else None,
                'modelEndpoint': str(row.modelEndpoint) if row.modelEndpoint else None
            }
            
            if row.queryTemplate:
                print(f"  - {action_name}: QueryAction (has SPARQL template)")
            
    def _execute_sparql_query(self, query_template: str, parameters: Dict[str, Any]) -> List[Dict]:
        """SPARQL ì¿¼ë¦¬ ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜"""
        # ì¿¼ë¦¬ í…œí”Œë¦¿ì—ì„œ íŒŒë¼ë¯¸í„° ì¹˜í™˜
        query = self._process_query_template(query_template, parameters)
        
        print("\nğŸ” SPARQL ì¿¼ë¦¬ ì‹¤í–‰:")
        print("-" * 60)
        print(query)
        print("-" * 60)
        
        # ì¿¼ë¦¬ ì‹¤í–‰
        try:
            results = self.data_graph.query(query)
            
            # ê²°ê³¼ë¥¼ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
            result_list = []
            for row in results:
                result_dict = {}
                for var in results.vars:
                    try:
                        # ë³€ìˆ˜ëª…ì€ Variable ê°ì²´ì´ë¯€ë¡œ ë¬¸ìì—´ë¡œ ë³€í™˜
                        var_name = str(var)
                        value = row[var]  # getattr ëŒ€ì‹  ë”•ì…”ë„ˆë¦¬ ìŠ¤íƒ€ì¼ ì ‘ê·¼
                        
                        if value is not None:
                            # URIì¸ ê²½ìš° ë§ˆì§€ë§‰ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                            if isinstance(value, URIRef):
                                result_dict[var_name] = str(value).split("#")[-1]
                            else:
                                result_dict[var_name] = str(value)
                        else:
                            result_dict[var_name] = None
                    except Exception as e:
                        print(f"   ë³€ìˆ˜ {var} ì ‘ê·¼ ì˜¤ë¥˜: {e}")
                        result_dict[str(var)] = None
                result_list.append(result_dict)
                
            print(f"\nâœ… ì¿¼ë¦¬ ê²°ê³¼: {len(result_list)}ê°œ ë ˆì½”ë“œ")
            print(f"   ë³€ìˆ˜ëª…: {list(results.vars)}")
            
            # ê²°ê³¼ ì¶œë ¥
            if result_list:
                print("\nê²°ê³¼ ìƒì„¸:")
                for i, result in enumerate(result_list, 1):
                    print(f"{i}. ", end="")
                    values = [f"{k}: {v}" for k, v in result.items() if v is not None]
                    if values:
                        print(" | ".join(values))
                    else:
                        print("(ëª¨ë“  í•„ë“œê°€ null)")
            else:
                print("\nâŒ ì¿¼ë¦¬ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    
            return result_list
            
        except Exception as e:
            print(f"âŒ ì¿¼ë¦¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
            print(f"   ì—ëŸ¬ íƒ€ì…: {type(e).__name__}")
            return []
    
    def _process_query_template(self, template: str, parameters: Dict[str, Any]) -> str:
        """ì¿¼ë¦¬ í…œí”Œë¦¿ ì²˜ë¦¬ - íŒŒë¼ë¯¸í„° ì¹˜í™˜"""
        query = template
        
        # %%FILTERS%% ì²˜ë¦¬
        if "%%FILTERS%%" in query:
            filters = []
            
            # Goal 1: Failed jobs with cooling
            if parameters.get("goal") == "query_failed_jobs_with_cooling":
                filters.append('?job prod:requiresCooling true .')
                filters.append('FILTER(?status = "Failed")')
                
                # ë‚ ì§œ í•„í„° ì²˜ë¦¬
                if "date" in parameters:
                    date = parameters["date"]
                    filters.append(f'FILTER(STRSTARTS(STR(?startTime), "{date}"))')
            else:
                # ë‚ ì§œ í•„í„° ì²˜ë¦¬
                if "date" in parameters:
                    date = parameters["date"]
                    filters.append(f'FILTER(STRSTARTS(STR(?startTime), "{date}"))')
                    
                # ì œí’ˆ í•„í„° ì²˜ë¦¬
                if "product_id" in parameters:
                    product_id = parameters["product_id"]
                    filters.append(f'FILTER(?product = prod:{product_id})')
                    
                # ë¨¸ì‹  í•„í„° ì²˜ë¦¬
                if "target_machine" in parameters:
                    machine = parameters["target_machine"]
                    filters.append(f'FILTER(?machine = prod:{machine})')
                
            filter_string = "\n            ".join(filters) if filters else ""
            query = query.replace("%%FILTERS%%", filter_string)
            
        # %%DATE_FILTER%% ì²˜ë¦¬
        if "%%DATE_FILTER%%" in query:
            date_filters = []
            if "date_range" in parameters:
                date_range = parameters["date_range"]
                if "start" in date_range:
                    date_filters.append(f'FILTER(?startTime >= "{date_range["start"]}"^^xsd:dateTime)')
                if "end" in date_range:
                    date_filters.append(f'FILTER(?startTime <= "{date_range["end"]}"^^xsd:dateTime)')
            
            date_filter_string = "\n            ".join(date_filters) if date_filters else ""
            query = query.replace("%%DATE_FILTER%%", date_filter_string)
            
        # ê¸°íƒ€ íŒŒë¼ë¯¸í„° ì¹˜í™˜
        for key, value in parameters.items():
            placeholder = f"%%{key.upper()}%%"
            if placeholder in query:
                query = query.replace(placeholder, str(value))
                
        return query
    
    def process_dsl(self, dsl_input: Dict[str, Any]) -> Dict[str, Any]:
        """DSL ì…ë ¥ì„ ì²˜ë¦¬í•˜ì—¬ ì‹¤í–‰ ê³„íš ìƒì„±"""
        print("\n" + "="*60)
        print("ğŸš€ DSL ì²˜ë¦¬ ì‹œì‘")
        print("="*60)
        
        print(f"\nğŸ“¥ DSL ì…ë ¥: {json.dumps(dsl_input, indent=2)}")
        
        # DSL goalì„ ì‹¤í–‰ ì˜¨í†¨ë¡œì§€ì˜ Goalë¡œ ë§¤í•‘
        dsl_goal = dsl_input.get("goal")
        execution_goal = self._find_execution_goal(dsl_goal)
        
        if not execution_goal:
            return {"error": f"Unknown goal: {dsl_goal}"}
        
        print(f"\nğŸ¯ ì‹¤í–‰ ëª©í‘œ: {execution_goal}")
        
        # Goalì— í•„ìš”í•œ Actionë“¤ ì°¾ê¸°
        required_actions = self._find_required_actions(execution_goal)
        print(f"\nğŸ“‹ í•„ìš”í•œ ì•¡ì…˜ë“¤: {[a.split('#')[-1] for a in required_actions]}")
        
        # ì‹¤í–‰ ê³„íš ìƒì„±
        execution_plan = self._generate_execution_plan(
            execution_goal, 
            required_actions, 
            dsl_input
        )
        
        # SPARQL ì¿¼ë¦¬ ì‹¤í–‰ (QueryActionì´ ìˆëŠ” ê²½ìš°)
        for step in execution_plan["steps"]:
            action_uri = f"{self.EXEC}{step['action']}"
            metadata = self.action_metadata.get(action_uri, {})
            
            # has_query í”Œë˜ê·¸ê°€ ìˆê±°ë‚˜ queryTemplateì´ ìˆëŠ” ê²½ìš°
            if step.get("has_query") or metadata.get('queryTemplate'):
                
                if metadata.get('queryTemplate'):
                    # ì¿¼ë¦¬ ì‹¤í–‰
                    results = self._execute_sparql_query(
                        metadata['queryTemplate'],
                        dsl_input
                    )
                    
                    # ê²°ê³¼ ì €ì¥
                    self.sparql_results[step['action']] = {
                        'query': self._process_query_template(metadata['queryTemplate'], dsl_input),
                        'results': results,
                        'count': len(results)
                    }
                    
                    # ì‹¤í–‰ ê³„íšì— ê²°ê³¼ ì¶”ê°€
                    step['sparql_results'] = self.sparql_results[step['action']]
        
        # ì „ì²´ SPARQL ê²°ê³¼ë¥¼ ì‹¤í–‰ ê³„íšì— ì¶”ê°€
        execution_plan['sparql_results'] = self.sparql_results
        
        print("\n" + "="*60)
        print("âœ… ì‹¤í–‰ ê³„íš ìƒì„± ì™„ë£Œ")
        print("="*60)
        
        # ì‹¤í–‰ ê³„íš ì¶œë ¥
        print(f"\nğŸ“„ ì‹¤í–‰ ê³„íš:\n{json.dumps(execution_plan, indent=2, ensure_ascii=False)}")
        
        return execution_plan
    
    def _find_execution_goal(self, dsl_goal: str) -> Optional[str]:
        """DSL goalì„ ì‹¤í–‰ ì˜¨í†¨ë¡œì§€ì˜ Goalë¡œ ë§¤í•‘"""
        # ë¸Œë¦¬ì§€ ì˜¨í†¨ë¡œì§€ì—ì„œ ë§¤í•‘ ì°¾ê¸°
        query = f"""
        SELECT ?execGoal WHERE {{
            ?bridgeGoal bridge:mapsGoal "{dsl_goal}" ;
                        bridge:toExecutionGoal ?execGoal .
        }}
        """
        
        print(f"\nğŸ” ë¸Œë¦¬ì§€ ì¿¼ë¦¬ ì‹¤í–‰:")
        print(query)
        
        results = list(self.bridge_graph.query(query))
        print(f"ê²°ê³¼: {len(results)}ê°œ")
        
        if results:
            exec_goal = str(results[0].execGoal)
            print(f"ë§¤í•‘ëœ ì‹¤í–‰ ëª©í‘œ: {exec_goal}")
            return exec_goal
        
        print(f"âŒ {dsl_goal}ì— ëŒ€í•œ ë§¤í•‘ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    def _find_required_actions(self, goal_uri: str) -> List[str]:
        """Goalì— í•„ìš”í•œ Actionë“¤ ì°¾ê¸°"""
        query = f"""
        SELECT ?action WHERE {{
            <{goal_uri}> exec:requiresAction ?action .
        }}
        ORDER BY ?action
        """
        
        results = self.exec_graph.query(query)
        return [str(row.action) for row in results]
    
    def _generate_execution_plan(self, goal: str, actions: List[str], 
                                parameters: Dict[str, Any]) -> Dict[str, Any]:
        """ì‹¤í–‰ ê³„íš ìƒì„±"""
        steps = []
        
        for i, action_uri in enumerate(actions):
            action_name = action_uri.split('#')[-1]
            metadata = self.action_metadata.get(action_uri, {})
            
            step = {
                "step": i + 1,
                "action": action_name,
                "action_type": metadata.get('actionType', 'Unknown'),
                "parameters": parameters
            }
            
            # ì•¡ì…˜ íƒ€ì…ë³„ ì¶”ê°€ ì •ë³´
            if metadata.get('queryTemplate'):
                step["has_query"] = True
                
            if metadata.get('enrichmentType'):
                step["enrichment_type"] = metadata['enrichmentType']
                
            if metadata.get('modelEndpoint'):
                step["model_endpoint"] = metadata['modelEndpoint']
                
            steps.append(step)
        
        return {
            "goal": goal.split('#')[-1],
            "timestamp": datetime.now().isoformat(),
            "steps": steps,
            "total_steps": len(steps)
        }


def main():
    """ë©”ì¸ í•¨ìˆ˜ - 4ê°€ì§€ ëª©í‘œ í…ŒìŠ¤íŠ¸"""
    # í”Œë˜ë„ˆ ì´ˆê¸°í™”
    planner = OntologyBasedExecutionPlannerWithSPARQL()
    
    # í…ŒìŠ¤íŠ¸í•  DSL ì…ë ¥ë“¤
    test_cases = [
        {
            "name": "Goal 1: ëƒ‰ê°ì´ í•„ìš”í•œ ì‹¤íŒ¨í•œ ì‘ì—… ì¡°íšŒ",
            "input": {
                "goal": "query_failed_jobs_with_cooling",
                "date": "2025-07-17"
            }
        },
        {
            "name": "Goal 2: ì œí’ˆ ì´ìƒ ê°ì§€",
            "input": {
                "goal": "detect_anomaly_for_product",
                "product_id": "Product-A1",
                "date_range": {
                    "start": "2025-07-17T00:00:00",
                    "end": "2025-07-17T23:59:59"
                },
                "target_machine": "CoolingMachine-01"
            }
        },
        {
            "name": "Goal 3: ì²« ì™„ë£Œ ì‹œê°„ ì˜ˆì¸¡",
            "input": {
                "goal": "predict_first_completion_time",
                "product_id": "Product-B2",
                "quantity": 100
            }
        },
        {
            "name": "Goal 4: ì œí’ˆ ìœ„ì¹˜ ì¶”ì ",
            "input": {
                "goal": "track_product_position",
                "product_id": "Product-C1"
            }
        }
    ]
    
    # ê° í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ì‹¤í–‰
    results = {}
    for test in test_cases:
        print(f"\n{'='*80}")
        print(f"ğŸ§ª í…ŒìŠ¤íŠ¸: {test['name']}")
        print(f"{'='*80}")
        
        result = planner.process_dsl(test["input"])
        results[test["input"]["goal"]] = result
        
        # ê²°ê³¼ ì €ì¥
        output_file = f"test_result_{test['input']['goal']}.json"
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(result, f, indent=2, ensure_ascii=False)
        print(f"\nğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
        
    # ì „ì²´ ê²°ê³¼ ìš”ì•½
    print(f"\n{'='*80}")
    print("ğŸ“Š ì „ì²´ í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
    print(f"{'='*80}")
    
    for goal, result in results.items():
        print(f"\n{goal}:")
        if 'sparql_results' in result:
            for action, query_result in result['sparql_results'].items():
                print(f"  - {action}: {query_result['count']}ê°œ ê²°ê³¼")
        else:
            print(f"  - ì‹¤í–‰ ë‹¨ê³„: {result.get('total_steps', 0)}ê°œ")


if __name__ == "__main__":
    main()