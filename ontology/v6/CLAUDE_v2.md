# CLAUDE_v2.md - AAS Integration v6: ê°œì„ ëœ ì•„í‚¤í…ì²˜ ì„¤ê³„

## ğŸ“‹ v6 ì•„í‚¤í…ì²˜ ê°œì„  ê³„íš (2025-08-06)

### 1. ë¬¸ì œì  ë¶„ì„

#### ì´ˆê¸° êµ¬í˜„ì˜ ë¬¸ì œ
- âŒ Mock Serverê°€ ì‹¤í–‰ë˜ì§€ ì•ŠìŒ
- âŒ ìŠ¤ëƒ…ìƒ· ë°ì´í„°ê°€ ë¡œì»¬ íŒŒì¼ë¡œë§Œ ì¡´ì¬
- âŒ AAS í‘œì¤€ Shell/Submodel êµ¬ì¡° ë¯¸ì‚¬ìš©
- âŒ ì‹¤ì œ REST API í˜¸ì¶œ ì—†ìŒ
- âŒ v5ì˜ ê²€ì¦ëœ êµ¬ì¡° ë¯¸í™œìš©

#### ê·¼ë³¸ ì›ì¸
1. ìŠ¤ëƒ…ìƒ·ì„ ë³„ë„ JSONìœ¼ë¡œ ì €ì¥ (AAS Serverì™€ ë¶„ë¦¬)
2. DataCollectorê°€ ë¡œì»¬ íŒŒì¼ ì§ì ‘ ì½ê¸°
3. Mock Server ë¯¸êµ¬í˜„ìœ¼ë¡œ API í…ŒìŠ¤íŠ¸ ë¶ˆê°€

### 2. ì˜¬ë°”ë¥¸ ì•„í‚¤í…ì²˜

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  ì˜¨í†¨ë¡œì§€ (ë‚˜ì¹¨ë°˜)                    â”‚
â”‚  - Goal â†’ Execution Plan ë§¤í•‘                        â”‚
â”‚  - Action ì‹œí€€ìŠ¤ ì •ì˜                                â”‚
â”‚  - Data Source ê²°ì •                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Execution Planner                       â”‚
â”‚  - ì˜¨í†¨ë¡œì§€ ì¿¼ë¦¬                                     â”‚
â”‚  - ì‹¤í–‰ ê³„íš ìƒì„±                                    â”‚
â”‚  - Action ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               AAS Client v2                          â”‚
â”‚  - HTTP REST API í˜¸ì¶œ                                â”‚
â”‚  - í‘œì¤€ AAS ì‘ë‹µ íŒŒì‹±                                â”‚
â”‚  - ì—ëŸ¬ ì²˜ë¦¬ ë° ì¬ì‹œë„                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Mock AAS Server v6                        â”‚
â”‚  - Flask ê¸°ë°˜ REST API                               â”‚
â”‚  - AAS Metamodel 3.0 ì¤€ìˆ˜                            â”‚
â”‚  - ì‹œì ë³„ ë™ì  ë°ì´í„° (T1-T5)                        â”‚
â”‚  - v5 êµ¬ì¡° ì¬ì‚¬ìš©                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### 3. ë°ì´í„° ëª¨ë¸ ì¬ì„¤ê³„

#### 3.1 AAS Shell êµ¬ì¡°
```json
{
  "modelType": "AssetAdministrationShell",
  "id": "urn:aas:Machine:CNC001",
  "idShort": "CNC001",
  "assetInformation": {
    "assetKind": "Instance",
    "globalAssetId": "urn:company:machines:cnc001"
  },
  "submodels": [
    {
      "type": "ModelReference",
      "keys": [{
        "type": "Submodel",
        "value": "urn:aas:sm:CNC001:Nameplate"
      }]
    },
    {
      "type": "ModelReference",
      "keys": [{
        "type": "Submodel",
        "value": "urn:aas:sm:CNC001:OperationalData"
      }]
    },
    {
      "type": "ModelReference",
      "keys": [{
        "type": "Submodel",
        "value": "urn:aas:sm:CNC001:JobHistory"
      }]
    }
  ]
}
```

#### 3.2 OperationalData Submodel (ì‹œì ë³„)
```json
{
  "modelType": "Submodel",
  "id": "urn:aas:sm:CNC001:OperationalData",
  "idShort": "OperationalData",
  "semanticId": {
    "type": "ExternalReference",
    "keys": [{
      "type": "GlobalReference",
      "value": "0173-1#02-AAV232#002"
    }]
  },
  "submodelElements": [
    {
      "modelType": "Property",
      "idShort": "Status",
      "value": "ERROR",
      "valueType": "xs:string",
      "timestamp": "2025-07-17T14:00:00"
    },
    {
      "modelType": "Property",
      "idShort": "Temperature",
      "value": "32.5",
      "valueType": "xs:float",
      "unit": "Â°C",
      "timestamp": "2025-07-17T14:00:00"
    },
    {
      "modelType": "Property",
      "idShort": "CoolantFlow",
      "value": "2.1",
      "valueType": "xs:float",
      "unit": "L/min",
      "timestamp": "2025-07-17T14:00:00"
    }
  ]
}
```

#### 3.3 JobHistory Submodel
```json
{
  "modelType": "Submodel",
  "id": "urn:aas:sm:CNC001:JobHistory",
  "idShort": "JobHistory",
  "submodelElements": [
    {
      "modelType": "SubmodelElementCollection",
      "idShort": "JOB-002",
      "value": [
        {
          "modelType": "Property",
          "idShort": "ProductId",
          "value": "Product-C1"
        },
        {
          "modelType": "Property",
          "idShort": "Status",
          "value": "FAILED"
        },
        {
          "modelType": "Property",
          "idShort": "FailureReason",
          "value": "temperature_exceeded"
        },
        {
          "modelType": "Property",
          "idShort": "Timestamp",
          "value": "2025-07-17T14:00:00"
        }
      ]
    }
  ]
}
```

### 4. êµ¬í˜„ ê³„íš

#### Phase 3-1: ìŠ¤ëƒ…ìƒ· â†’ AAS ë³€í™˜
```python
# aas_data/converter.py
class SnapshotToAASConverter:
    def convert_machine(self, machine_data, timepoint):
        """ê¸°ê³„ ë°ì´í„°ë¥¼ AAS Shellë¡œ ë³€í™˜"""
        return {
            "modelType": "AssetAdministrationShell",
            "id": f"urn:aas:Machine:{machine_data['machine_id']}",
            "submodels": [
                self.create_nameplate(machine_data),
                self.create_operational_data(machine_data, timepoint),
                self.create_job_history(machine_data, timepoint)
            ]
        }
    
    def convert_product(self, product_data):
        """ì œí’ˆ ë°ì´í„°ë¥¼ AAS Shellë¡œ ë³€í™˜"""
        return {
            "modelType": "AssetAdministrationShell",
            "id": f"urn:aas:Product:{product_data['product_id']}",
            "submodels": [
                self.create_specification(product_data),
                self.create_requirements(product_data)
            ]
        }
```

#### Phase 3-2: Mock Server êµ¬í˜„
```python
# src/mock_server.py
from flask import Flask, jsonify, request
import json
from datetime import datetime

app = Flask(__name__)

class AASMockServer:
    def __init__(self):
        self.shells = {}  # ë³€í™˜ëœ AAS Shell ë°ì´í„°
        self.submodels = {}  # ë³€í™˜ëœ Submodel ë°ì´í„°
        self.load_data()
    
    def load_data(self):
        """ìŠ¤ëƒ…ìƒ· ë°ì´í„°ë¥¼ AAS í˜•ì‹ìœ¼ë¡œ ë¡œë“œ"""
        converter = SnapshotToAASConverter()
        for timepoint in ["T1", "T2", "T3", "T4", "T5"]:
            snapshot = load_snapshot(timepoint)
            self.process_snapshot(snapshot, timepoint, converter)
    
    def get_operational_data(self, machine_id, timestamp):
        """ì‹œì ë³„ ìš´ì˜ ë°ì´í„° ë°˜í™˜"""
        timepoint = self.map_timestamp_to_timepoint(timestamp)
        submodel_id = f"urn:aas:sm:{machine_id}:OperationalData"
        return self.submodels[timepoint].get(submodel_id)

@app.route('/shells', methods=['GET'])
def get_shells():
    """ëª¨ë“  AAS Shell ì¡°íšŒ"""
    return jsonify(list(server.shells.values()))

@app.route('/shells/<aas_id>', methods=['GET'])
def get_shell(aas_id):
    """íŠ¹ì • AAS Shell ì¡°íšŒ"""
    shell = server.shells.get(aas_id)
    if shell:
        return jsonify(shell)
    return jsonify({"error": "Shell not found"}), 404

@app.route('/submodels/<submodel_id>', methods=['GET'])
def get_submodel(submodel_id):
    """Submodel ì¡°íšŒ (ì‹œì ë³„)"""
    timestamp = request.args.get('timestamp')
    if timestamp:
        # ì‹œì ë³„ ë°ì´í„° ë°˜í™˜
        timepoint = map_timestamp_to_timepoint(timestamp)
        submodel = server.get_submodel_at_time(submodel_id, timepoint)
    else:
        # ìµœì‹  ë°ì´í„° ë°˜í™˜
        submodel = server.get_latest_submodel(submodel_id)
    
    if submodel:
        return jsonify(submodel)
    return jsonify({"error": "Submodel not found"}), 404

@app.route('/api/machines/cooling-required', methods=['GET'])
def get_cooling_machines():
    """ëƒ‰ê° í•„ìš” ê¸°ê³„ ì¡°íšŒ (Goal 1)"""
    cooling_machines = []
    for shell in server.shells.values():
        if "Machine" in shell['id']:
            # TechnicalDataì—ì„œ cooling_required í™•ì¸
            tech_data = server.get_submodel(f"{shell['id']}:TechnicalData")
            if tech_data and tech_data.get('cooling_required'):
                cooling_machines.append(shell)
    return jsonify(cooling_machines)

@app.route('/api/jobs/failed', methods=['GET'])
def get_failed_jobs():
    """ì‹¤íŒ¨í•œ ì‘ì—… ì¡°íšŒ (Goal 1)"""
    date = request.args.get('date', '2025-07-17')
    timepoint = "T4"  # ì‹¤íŒ¨ ì‹œì 
    
    failed_jobs = []
    for machine_id in server.get_machine_ids():
        job_history = server.get_submodel_at_time(
            f"urn:aas:sm:{machine_id}:JobHistory", 
            timepoint
        )
        if job_history:
            for element in job_history.get('submodelElements', []):
                if element.get('Status') == 'FAILED':
                    failed_jobs.append(element)
    
    return jsonify(failed_jobs)
```

#### Phase 3-3: AAS Client êµ¬í˜„
```python
# src/aas_client.py
import requests
from typing import Dict, List, Optional, Any
import logging

class AASClient:
    """AAS REST API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, base_url: str = "http://localhost:5001"):
        self.base_url = base_url
        self.session = requests.Session()
        self.logger = logging.getLogger(__name__)
    
    def get_shells(self) -> List[Dict[str, Any]]:
        """ëª¨ë“  Shell ì¡°íšŒ"""
        try:
            response = self.session.get(f"{self.base_url}/shells")
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            self.logger.error(f"Failed to get shells: {e}")
            return []
    
    def get_shell(self, aas_id: str) -> Optional[Dict[str, Any]]:
        """íŠ¹ì • Shell ì¡°íšŒ"""
        try:
            response = self.session.get(f"{self.base_url}/shells/{aas_id}")
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            self.logger.error(f"Failed to get shell {aas_id}: {e}")
            return None
    
    def get_submodel(self, submodel_id: str, 
                    timestamp: Optional[str] = None) -> Optional[Dict[str, Any]]:
        """Submodel ì¡°íšŒ"""
        try:
            url = f"{self.base_url}/submodels/{submodel_id}"
            params = {"timestamp": timestamp} if timestamp else {}
            response = self.session.get(url, params=params)
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            self.logger.error(f"Failed to get submodel {submodel_id}: {e}")
            return None
    
    def get_cooling_machines(self) -> List[Dict[str, Any]]:
        """ëƒ‰ê° í•„ìš” ê¸°ê³„ ì¡°íšŒ"""
        try:
            response = self.session.get(f"{self.base_url}/api/machines/cooling-required")
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            self.logger.error(f"Failed to get cooling machines: {e}")
            return []
    
    def get_failed_jobs(self, date: str) -> List[Dict[str, Any]]:
        """ì‹¤íŒ¨í•œ ì‘ì—… ì¡°íšŒ"""
        try:
            response = self.session.get(
                f"{self.base_url}/api/jobs/failed",
                params={"date": date}
            )
            response.raise_for_status()
            return response.json()
        except requests.exceptions.RequestException as e:
            self.logger.error(f"Failed to get failed jobs: {e}")
            return []
```

#### Phase 3-4: DataCollector ìˆ˜ì •
```python
# src/data_collector.py (ìˆ˜ì •)
class DataCollector:
    def __init__(self):
        self.aas_client = AASClient()
        self.fallback_to_local = False
    
    def collect_from_aas(self, endpoint: str, params: Dict = None):
        """AAS Serverì—ì„œ ë°ì´í„° ìˆ˜ì§‘"""
        # 1ì°¨: AAS REST API
        if endpoint.startswith("/shells"):
            return self.aas_client.get_shell(endpoint.split("/")[-1])
        elif endpoint.startswith("/submodels"):
            submodel_id = endpoint.split("/")[-1]
            timestamp = params.get("timestamp") if params else None
            return self.aas_client.get_submodel(submodel_id, timestamp)
        elif "cooling-required" in endpoint:
            return self.aas_client.get_cooling_machines()
        elif "failed" in endpoint:
            date = params.get("date", "2025-07-17")
            return self.aas_client.get_failed_jobs(date)
        
        # 2ì°¨: Fallback to local snapshot
        if self.fallback_to_local:
            return self.collect_from_snapshot(...)
```

#### Phase 3-5: ExecutionPlanner í†µí•©
```python
# src/execution_planner.py (ìˆ˜ì •)
class ExecutionPlanner:
    def __init__(self):
        self.ontology_manager = OntologyManager()
        self.data_collector = DataCollector()
        self.aas_client = AASClient()
    
    def _execute_aas_action(self, action: Dict, parameters: Dict):
        """AAS API ì•¡ì…˜ ì‹¤í–‰"""
        endpoint = action.get("endpoint")
        
        # íŒŒë¼ë¯¸í„° ì¹˜í™˜
        for key, value in parameters.items():
            endpoint = endpoint.replace(f"{{{key}}}", str(value))
        
        # ì‹œì  ì •ë³´ ì¶”ê°€
        params = {}
        if action.get("snapshotTime"):
            params["timestamp"] = action["snapshotTime"]
        
        # AAS Clientë¡œ API í˜¸ì¶œ
        return self.data_collector.collect_from_aas(endpoint, params)
    
    def _execute_snapshot_action(self, action: Dict):
        """ìŠ¤ëƒ…ìƒ· ì•¡ì…˜ ì‹¤í–‰ (AAS Server ê²½ìœ )"""
        timepoint = self.extract_timepoint(action.get("snapshotTime"))
        data_path = action.get("dataPath")
        
        # AAS Serverì—ì„œ ì‹œì ë³„ Submodel ì¡°íšŒ
        if data_path == "jobs":
            return self.aas_client.get_failed_jobs("2025-07-17")
        elif data_path == "machines":
            timestamp = self.timepoint_to_timestamp(timepoint)
            machines = []
            for shell in self.aas_client.get_shells():
                if "Machine" in shell['id']:
                    machine_id = shell['idShort']
                    operational_data = self.aas_client.get_submodel(
                        f"urn:aas:sm:{machine_id}:OperationalData",
                        timestamp
                    )
                    machines.append(operational_data)
            return machines
```

### 5. íŒŒì¼ êµ¬ì¡°

```
v6/
â”œâ”€â”€ ontology/               âœ… ì™„ë£Œ
â”‚   â”œâ”€â”€ execution-ontology.ttl
â”‚   â”œâ”€â”€ domain-ontology.ttl
â”‚   â””â”€â”€ bridge-ontology.ttl
â”œâ”€â”€ snapshots/              âœ… ì™„ë£Œ
â”‚   â””â”€â”€ snapshot_T*.json
â”œâ”€â”€ aas_data/              ğŸ”„ ì¶”ê°€ í•„ìš”
â”‚   â”œâ”€â”€ converter.py       # ìŠ¤ëƒ…ìƒ· â†’ AAS ë³€í™˜
â”‚   â”œâ”€â”€ shells/            # ë³€í™˜ëœ AAS Shell JSON
â”‚   â””â”€â”€ submodels/         # ë³€í™˜ëœ Submodel JSON
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ mock_server.py     ğŸ”„ ìƒˆë¡œ êµ¬í˜„
â”‚   â”œâ”€â”€ aas_client.py      ğŸ”„ ìƒˆë¡œ êµ¬í˜„
â”‚   â”œâ”€â”€ aas_models.py      ğŸ”„ v5ì—ì„œ ë³µì‚¬
â”‚   â”œâ”€â”€ ontology_manager.py âœ… ì™„ë£Œ
â”‚   â”œâ”€â”€ data_collector.py   ğŸ”„ ìˆ˜ì • í•„ìš”
â”‚   â””â”€â”€ execution_planner.py ğŸ”„ ìˆ˜ì • í•„ìš”
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ start_server.sh    ğŸ”„ ì„œë²„ ì‹œì‘ ìŠ¤í¬ë¦½íŠ¸
â”‚   â””â”€â”€ setup_env.sh       ğŸ”„ í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
â””â”€â”€ test_*.py              ğŸ”„ í…ŒìŠ¤íŠ¸ ìˆ˜ì •

```

### 6. í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

#### Goal 1 ì‹¤í–‰ íë¦„
```
1. Start Mock Server
   $ python src/mock_server.py

2. Run Test
   $ python test_goal1_with_server.py

3. Execution Flow:
   a. ì˜¨í†¨ë¡œì§€ â†’ 5ë‹¨ê³„ ì‹¤í–‰ ê³„íš
   b. SPARQL â†’ ëƒ‰ê° ì œí’ˆ ì¡°íšŒ
   c. AAS API â†’ GET /api/machines/cooling-required
   d. SNAPSHOT â†’ GET /submodels/JobHistory?timestamp=T4
   e. FILTER â†’ ì‹¤íŒ¨ ì‘ì—… í•„í„°ë§
   f. TRANSFORM â†’ ë¦¬í¬íŠ¸ ìƒì„±

4. Expected Result:
   - 3 failed jobs found (JOB-001, JOB-002, JOB-003)
   - All from cooling-required machines
   - All cooling-required products
```

### 7. ì£¼ìš” ê°œì„ ì‚¬í•­

1. **AAS í‘œì¤€ ì¤€ìˆ˜**
   - Metamodel 3.0 êµ¬ì¡° ì‚¬ìš©
   - í‘œì¤€ REST API ì—”ë“œí¬ì¸íŠ¸
   - SemanticId ì‚¬ìš©

2. **v5 ìì‚° í™œìš©**
   - ê²€ì¦ëœ Mock Server êµ¬ì¡°
   - AAS ëª¨ë¸ í´ë˜ìŠ¤
   - í‘œì¤€ í…œí”Œë¦¿

3. **ë™ì  ë°ì´í„° ì²˜ë¦¬**
   - ì‹œì ë³„ Submodel ì¡°íšŒ
   - timestamp íŒŒë¼ë¯¸í„° ì§€ì›
   - ì‹¤ì‹œê°„ ìƒíƒœ ì‹œë®¬ë ˆì´ì…˜

4. **ì˜¨í†¨ë¡œì§€ í†µí•©**
   - dataSource ì •ë³´ í™œìš©
   - endpoint ë™ì  êµ¬ì„±
   - fallback ì²´ì¸ êµ¬í˜„

---

## ğŸ“‹ Goals 2-4 êµ¬í˜„ ê³„íš (2025-08-06)

### Goal 2: Detect Anomaly for Product

#### ëª©í‘œ
ì œí’ˆì˜ ì„¼ì„œ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì´ìƒ íŒ¨í„´ì„ ê°ì§€í•˜ê³  ì˜ˆì¸¡

#### ë°ì´í„° ì†ŒìŠ¤
1. **AAS Server (ì •ì )**
   - Product Shell ì •ë³´
   - Specification Submodel (ì •ìƒ ë²”ìœ„)
   - Requirements Submodel (í’ˆì§ˆ ê¸°ì¤€)

2. **Snapshots (ë™ì )**
   - T1-T5 ì‹œì ë³„ ì„¼ì„œ ë°ì´í„°
   - Temperature, Pressure, Vibration ì¸¡ì •ê°’
   - í’ˆì§ˆ ì¸¡ì • ë°ì´í„°

3. **Docker Container (AI/ML)**
   - ì´ìƒ ê°ì§€ ëª¨ë¸ ì‹¤í–‰
   - TensorFlow/PyTorch ê¸°ë°˜ ë¶„ì„
   - ì‹œê³„ì—´ íŒ¨í„´ ë¶„ì„

#### ì‹¤í–‰ ê³„íš
```python
def execute_goal2(self, product_id: str, timepoint: str = "T4"):
    # 1. AASì—ì„œ ì œí’ˆ ì •ë³´ ì¡°íšŒ
    product_shell = self.aas_client.get_shell(f"urn:aas:Product:{product_id}")
    spec = self.aas_client.get_submodel(f"urn:aas:sm:{product_id}:Specification")
    
    # 2. ì‹œì ë³„ ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘
    sensor_data = []
    for tp in ["T1", "T2", "T3", "T4", "T5"]:
        timestamp = self.timepoint_to_timestamp(tp)
        data = self.aas_client.get_submodel(
            f"urn:aas:sm:{product_id}:SensorData",
            timestamp
        )
        sensor_data.append(data)
    
    # 3. Docker ì»¨í…Œì´ë„ˆë¡œ ì´ìƒ ê°ì§€ ì‹¤í–‰
    container_result = self.run_docker_container(
        image="anomaly-detector:latest",
        data={
            "sensor_data": sensor_data,
            "specification": spec,
            "threshold": 0.95
        }
    )
    
    # 4. ê²°ê³¼ ë¶„ì„ ë° ë¦¬í¬íŠ¸ ìƒì„±
    anomalies = container_result.get("anomalies", [])
    confidence = container_result.get("confidence", 0)
    
    return {
        "product_id": product_id,
        "anomalies_detected": len(anomalies) > 0,
        "anomaly_points": anomalies,
        "confidence": confidence,
        "recommendation": self.generate_recommendation(anomalies)
    }
```

#### AAS Submodel í™•ì¥
```json
// SensorData Submodel (ì‹œì ë³„)
{
  "modelType": "Submodel",
  "id": "urn:aas:sm:Product-B1:SensorData",
  "idShort": "SensorData",
  "submodelElements": [
    {
      "modelType": "Property",
      "idShort": "Temperature",
      "value": "85.2",
      "valueType": "xs:float",
      "unit": "Â°C",
      "timestamp": "2025-07-17T14:00:00"
    },
    {
      "modelType": "Property",
      "idShort": "Pressure",
      "value": "2.8",
      "valueType": "xs:float",
      "unit": "bar"
    },
    {
      "modelType": "Property",
      "idShort": "Vibration",
      "value": "0.45",
      "valueType": "xs:float",
      "unit": "mm/s"
    },
    {
      "modelType": "Property",
      "idShort": "QualityScore",
      "value": "0.92",
      "valueType": "xs:float"
    }
  ]
}
```

### Goal 3: Predict Completion Time

#### ëª©í‘œ
í˜„ì¬ ì‘ì—… ìƒíƒœì™€ ì´ë ¥ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì—… ì™„ë£Œ ì‹œê°„ ì˜ˆì¸¡

#### ë°ì´í„° ì†ŒìŠ¤
1. **AAS Server**
   - Machine Shell (ì¥ë¹„ ì‚¬ì–‘)
   - TechnicalData (ì²˜ë¦¬ ëŠ¥ë ¥)
   - MaintenanceHistory (ìœ ì§€ë³´ìˆ˜ ì´ë ¥)

2. **Snapshots**
   - JobHistory (ê³¼ê±° ì‘ì—… ì´ë ¥)
   - Current Job Status
   - Queue Status

3. **Docker Container**
   - ì‹œê°„ ì˜ˆì¸¡ ML ëª¨ë¸
   - íšŒê·€ ë¶„ì„ ì—”ì§„

#### ì‹¤í–‰ ê³„íš
```python
def execute_goal3(self, job_id: str, machine_id: str):
    # 1. í˜„ì¬ ì‘ì—… ìƒíƒœ ì¡°íšŒ
    current_job = self.aas_client.get_submodel(
        f"urn:aas:sm:{machine_id}:CurrentJob"
    )
    
    # 2. ê¸°ê³„ ì„±ëŠ¥ ë°ì´í„°
    tech_data = self.aas_client.get_submodel(
        f"urn:aas:sm:{machine_id}:TechnicalData"
    )
    
    # 3. ê³¼ê±° ì‘ì—… ì´ë ¥ (í•™ìŠµ ë°ì´í„°)
    job_history = self.aas_client.get_submodel(
        f"urn:aas:sm:{machine_id}:JobHistory"
    )
    
    # 4. Docker ì»¨í…Œì´ë„ˆë¡œ ì˜ˆì¸¡ ì‹¤í–‰
    prediction = self.run_docker_container(
        image="completion-predictor:latest",
        data={
            "current_job": current_job,
            "machine_specs": tech_data,
            "historical_jobs": job_history,
            "algorithm": "xgboost"
        }
    )
    
    # 5. ì˜ˆì¸¡ ê²°ê³¼ ì²˜ë¦¬
    return {
        "job_id": job_id,
        "machine_id": machine_id,
        "current_progress": current_job.get("progress", 0),
        "predicted_completion": prediction.get("completion_time"),
        "confidence_interval": prediction.get("confidence_interval"),
        "factors": prediction.get("influencing_factors", [])
    }
```

#### CurrentJob Submodel
```json
{
  "modelType": "Submodel",
  "id": "urn:aas:sm:CNC001:CurrentJob",
  "idShort": "CurrentJob",
  "submodelElements": [
    {
      "modelType": "Property",
      "idShort": "JobId",
      "value": "JOB-005"
    },
    {
      "modelType": "Property",
      "idShort": "ProductId",
      "value": "Product-A1"
    },
    {
      "modelType": "Property",
      "idShort": "StartTime",
      "value": "2025-07-17T08:00:00"
    },
    {
      "modelType": "Property",
      "idShort": "Progress",
      "value": "65",
      "valueType": "xs:integer",
      "unit": "%"
    },
    {
      "modelType": "Property",
      "idShort": "EstimatedRemaining",
      "value": "45",
      "valueType": "xs:integer",
      "unit": "minutes"
    }
  ]
}
```

### Goal 4: Track Product Position

#### ëª©í‘œ
ì œí’ˆì˜ ì‹¤ì‹œê°„ ìœ„ì¹˜ì™€ ì´ë™ ê²½ë¡œë¥¼ ì¶”ì í•˜ê³  ì‹œê°í™”

#### ë°ì´í„° ì†ŒìŠ¤
1. **AAS Server**
   - Product Shell
   - TrackingInfo Submodel
   - LocationHistory Submodel

2. **Snapshots**
   - ì‹œì ë³„ ìœ„ì¹˜ ë°ì´í„°
   - RFID/ë°”ì½”ë“œ ìŠ¤ìº” ì´ë ¥

3. **ì‹¤ì‹œê°„ ì—…ë°ì´íŠ¸**
   - WebSocket ë˜ëŠ” SSE
   - ìœ„ì¹˜ ì„¼ì„œ ë°ì´í„°

#### ì‹¤í–‰ ê³„íš
```python
def execute_goal4(self, product_id: str, include_history: bool = True):
    # 1. ì œí’ˆ Shell ì¡°íšŒ
    product_shell = self.aas_client.get_shell(
        f"urn:aas:Product:{product_id}"
    )
    
    # 2. í˜„ì¬ ìœ„ì¹˜ ì¡°íšŒ
    current_location = self.aas_client.get_submodel(
        f"urn:aas:sm:{product_id}:TrackingInfo"
    )
    
    # 3. ìœ„ì¹˜ ì´ë ¥ ì¡°íšŒ (ì˜µì…˜)
    location_history = []
    if include_history:
        for tp in ["T1", "T2", "T3", "T4", "T5"]:
            timestamp = self.timepoint_to_timestamp(tp)
            location = self.aas_client.get_submodel(
                f"urn:aas:sm:{product_id}:TrackingInfo",
                timestamp
            )
            if location:
                location_history.append({
                    "timepoint": tp,
                    "location": location.get("CurrentLocation"),
                    "timestamp": timestamp
                })
    
    # 4. ì´ë™ ê²½ë¡œ ë¶„ì„
    movement_pattern = self.analyze_movement(location_history)
    
    # 5. ë‹¤ìŒ ìœ„ì¹˜ ì˜ˆì¸¡ (ì„ íƒì )
    next_location = self.predict_next_location(
        current_location, 
        movement_pattern
    )
    
    return {
        "product_id": product_id,
        "current_location": {
            "zone": current_location.get("Zone"),
            "station": current_location.get("Station"),
            "coordinates": current_location.get("Coordinates"),
            "last_update": current_location.get("LastUpdate")
        },
        "location_history": location_history,
        "movement_pattern": movement_pattern,
        "predicted_next": next_location,
        "status": current_location.get("Status", "IN_TRANSIT")
    }
```

#### TrackingInfo Submodel
```json
{
  "modelType": "Submodel",
  "id": "urn:aas:sm:Product-B1:TrackingInfo",
  "idShort": "TrackingInfo",
  "submodelElements": [
    {
      "modelType": "Property",
      "idShort": "Zone",
      "value": "Production"
    },
    {
      "modelType": "Property",
      "idShort": "Station",
      "value": "CNC001"
    },
    {
      "modelType": "Property",
      "idShort": "Coordinates",
      "value": "{'x': 120.5, 'y': 45.2, 'z': 0}"
    },
    {
      "modelType": "Property",
      "idShort": "LastUpdate",
      "value": "2025-07-17T14:30:00"
    },
    {
      "modelType": "Property",
      "idShort": "Status",
      "value": "PROCESSING"
    },
    {
      "modelType": "Property",
      "idShort": "RFID",
      "value": "TAG-001234"
    }
  ]
}
```

### Docker Container Integration

#### Container êµ¬ì¡°
```yaml
# docker-compose.yml
version: '3.8'
services:
  anomaly-detector:
    image: anomaly-detector:latest
    ports:
      - "5002:5000"
    environment:
      - MODEL_PATH=/models/anomaly_model.pkl
      - THRESHOLD=0.95
    volumes:
      - ./models:/models
      - ./data:/data
  
  completion-predictor:
    image: completion-predictor:latest
    ports:
      - "5003:5000"
    environment:
      - MODEL_TYPE=xgboost
      - TRAINING_DATA=/data/historical_jobs.csv
    volumes:
      - ./models:/models
      - ./data:/data
```

#### Container ì‹¤í–‰ ë¡œì§
```python
class ContainerExecutor:
    def __init__(self):
        self.docker_client = docker.from_env()
    
    def run_container(self, image: str, data: Dict, timeout: int = 30):
        """Docker ì»¨í…Œì´ë„ˆ ì‹¤í–‰ ë° ê²°ê³¼ ë°˜í™˜"""
        try:
            # ë°ì´í„°ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            input_file = f"/tmp/input_{uuid.uuid4()}.json"
            with open(input_file, 'w') as f:
                json.dump(data, f)
            
            # ì»¨í…Œì´ë„ˆ ì‹¤í–‰
            container = self.docker_client.containers.run(
                image,
                command=f"python analyze.py {input_file}",
                volumes={'/tmp': {'bind': '/data', 'mode': 'rw'}},
                detach=True
            )
            
            # ê²°ê³¼ ëŒ€ê¸° (timeout)
            result = container.wait(timeout=timeout)
            output = container.logs()
            
            # ê²°ê³¼ íŒŒì‹±
            return json.loads(output)
            
        except Exception as e:
            logger.error(f"Container execution failed: {e}")
            # Fallback to simple analysis
            return self.simple_analysis(data)
    
    def simple_analysis(self, data: Dict):
        """Docker ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ë¶„ì„ ìˆ˜í–‰"""
        # ê¸°ë³¸ ê·œì¹™ ê¸°ë°˜ ë¶„ì„
        return {
            "status": "fallback",
            "result": "basic_analysis",
            "confidence": 0.7
        }
```

### Mock Server í™•ì¥ (Goals 2-4)

```python
# Mock Serverì— ì¶”ê°€í•  ì—”ë“œí¬ì¸íŠ¸

@app.route('/api/products/<product_id>/sensor-data', methods=['GET'])
def get_product_sensor_data(product_id):
    """ì œí’ˆ ì„¼ì„œ ë°ì´í„° ì¡°íšŒ (Goal 2)"""
    timepoint = request.args.get('timepoint', 'T4')
    sensor_data_id = f"urn:aas:sm:{product_id}:SensorData"
    
    data = server.get_submodel_at_time(sensor_data_id, timepoint)
    if data:
        return jsonify(data)
    return jsonify({"error": "Sensor data not found"}), 404

@app.route('/api/machines/<machine_id>/current-job', methods=['GET'])
def get_current_job(machine_id):
    """í˜„ì¬ ì‘ì—… ì¡°íšŒ (Goal 3)"""
    job_id = f"urn:aas:sm:{machine_id}:CurrentJob"
    job = server.get_latest_submodel(job_id)
    
    if job:
        return jsonify(job)
    return jsonify({"error": "No current job"}), 404

@app.route('/api/products/<product_id>/location', methods=['GET'])
def get_product_location(product_id):
    """ì œí’ˆ ìœ„ì¹˜ ì¡°íšŒ (Goal 4)"""
    include_history = request.args.get('history', 'false').lower() == 'true'
    
    tracking_id = f"urn:aas:sm:{product_id}:TrackingInfo"
    current = server.get_latest_submodel(tracking_id)
    
    result = {
        "product_id": product_id,
        "current_location": current
    }
    
    if include_history:
        history = []
        for tp in ["T1", "T2", "T3", "T4", "T5"]:
            location = server.get_submodel_at_time(tracking_id, tp)
            if location:
                history.append({
                    "timepoint": tp,
                    "location": location
                })
        result["history"] = history
    
    return jsonify(result)
```

### í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

#### Goal 2 í…ŒìŠ¤íŠ¸
```python
# test_goal2.py
def test_goal2_anomaly_detection():
    executor = ExecutionPlanner()
    
    result = executor.execute_goal({
        "goal": "detect_anomaly",
        "parameters": {
            "product_id": "Product-B1",
            "timepoint": "T4"
        }
    })
    
    assert result["anomalies_detected"] == True
    assert result["confidence"] > 0.9
    assert "temperature_spike" in result["anomaly_points"]
```

#### Goal 3 í…ŒìŠ¤íŠ¸
```python
# test_goal3.py
def test_goal3_completion_prediction():
    executor = ExecutionPlanner()
    
    result = executor.execute_goal({
        "goal": "predict_completion",
        "parameters": {
            "job_id": "JOB-005",
            "machine_id": "CNC001"
        }
    })
    
    assert "predicted_completion" in result
    assert result["current_progress"] == 65
    assert result["confidence_interval"][0] < result["predicted_completion"]
```

#### Goal 4 í…ŒìŠ¤íŠ¸
```python
# test_goal4.py
def test_goal4_product_tracking():
    executor = ExecutionPlanner()
    
    result = executor.execute_goal({
        "goal": "track_product",
        "parameters": {
            "product_id": "Product-B1",
            "include_history": True
        }
    })
    
    assert result["current_location"]["station"] == "CNC001"
    assert len(result["location_history"]) == 5
    assert result["status"] == "PROCESSING"
```

### êµ¬í˜„ ìš°ì„ ìˆœìœ„

1. **Phase 1: Goal 4 (ê°€ì¥ ê°„ë‹¨)**
   - AAS Submodel í™•ì¥ (TrackingInfo)
   - Mock Server ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
   - ìœ„ì¹˜ ì¶”ì  ë¡œì§ êµ¬í˜„
   - í…ŒìŠ¤íŠ¸ ì‘ì„±

2. **Phase 2: Goal 2 (ì¤‘ê°„ ë³µì¡ë„)**
   - SensorData Submodel ì¶”ê°€
   - ì´ìƒ ê°ì§€ ë¡œì§ (ê·œì¹™ ê¸°ë°˜)
   - Docker ì»¨í…Œì´ë„ˆ ì‹œë®¬ë ˆì´ì…˜
   - í…ŒìŠ¤íŠ¸ ë° ê²€ì¦

3. **Phase 3: Goal 3 (ê°€ì¥ ë³µì¡)**
   - CurrentJob Submodel
   - ì˜ˆì¸¡ ëª¨ë¸ ì‹œë®¬ë ˆì´ì…˜
   - ì´ë ¥ ë°ì´í„° ë¶„ì„
   - í†µí•© í…ŒìŠ¤íŠ¸

### ì˜ˆìƒ ì¼ì •
- Goal 4: 1ì¼ (ìœ„ì¹˜ ì¶”ì )
- Goal 2: 2ì¼ (ì´ìƒ ê°ì§€)
- Goal 3: 2ì¼ (ì™„ë£Œ ì‹œê°„ ì˜ˆì¸¡)
- í†µí•© í…ŒìŠ¤íŠ¸: 1ì¼
- ë¬¸ì„œí™”: 1ì¼

**ì´ ì˜ˆìƒ ê¸°ê°„**: 1ì£¼ì¼

---

**ì‘ì„±ì¼**: 2025-08-06  
**ë²„ì „**: v6 Goals 2-4 êµ¬í˜„ ê³„íš  
**ìƒíƒœ**: Goal 1 ì™„ë£Œ, Goals 2-4 ê³„íš ìˆ˜ë¦½ ì™„ë£Œ