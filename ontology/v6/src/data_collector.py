"""
Data Collector for v6 AAS Integration
ë‹¤ì–‘í•œ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ë°ì´í„° ìˆ˜ì§‘ (AAS API, Snapshot, SPARQL)
"""

import json
import os
from datetime import datetime
from typing import Dict, List, Any, Optional
import logging

try:
    import requests
    HAS_REQUESTS = True
except ImportError:
    HAS_REQUESTS = False
    logging.warning("âš ï¸ requests module not available, using snapshot data only")

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class DataCollector:
    """ë‹¤ì¤‘ ì†ŒìŠ¤ ë°ì´í„° ìˆ˜ì§‘ê¸°"""
    
    def __init__(self, config: Optional[Dict[str, Any]] = None):
        self.config = config or self.get_default_config()
        self.snapshot_dir = "./snapshots"
        self.cache = {}  # ìºì‹œ
        
    def get_default_config(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ì„¤ì •"""
        return {
            "aas_server": {
                "primary": "http://localhost:5001",
                "fallback": "http://localhost:5002"
            },
            "sparql_endpoint": "http://localhost:3030/production/sparql",
            "snapshot_store": "../snapshots",
            "timeout": 5
        }
    
    def collect_from_aas(self, endpoint: str, method: str = "GET", 
                        params: Optional[Dict] = None) -> Optional[Dict[str, Any]]:
        """AAS Serverì—ì„œ ë°ì´í„° ìˆ˜ì§‘"""
        if not HAS_REQUESTS:
            logger.warning(f"âš ï¸ Requests not available, skipping AAS: {endpoint}")
            return None
            
        # ìš°ì„  Mock Server ì‹œë„
        base_url = self.config["aas_server"]["primary"]
        url = f"{base_url}{endpoint}"
        
        try:
            response = requests.request(
                method=method,
                url=url,
                params=params,
                timeout=self.config["timeout"]
            )
            
            if response.status_code == 200:
                logger.info(f"âœ… Collected from AAS: {endpoint}")
                return response.json()
            else:
                logger.warning(f"âš ï¸ AAS returned {response.status_code}: {endpoint}")
                
        except requests.exceptions.RequestException as e:
            logger.warning(f"âš ï¸ AAS request failed: {e}")
            
        # Fallback to secondary server
        if self.config["aas_server"]["fallback"]:
            return self._try_fallback_aas(endpoint, method, params)
            
        return None
    
    def _try_fallback_aas(self, endpoint: str, method: str, 
                         params: Optional[Dict]) -> Optional[Dict[str, Any]]:
        """Fallback AAS Server ì‹œë„"""
        if not HAS_REQUESTS:
            return None
            
        base_url = self.config["aas_server"]["fallback"]
        url = f"{base_url}{endpoint}"
        
        try:
            response = requests.request(
                method=method,
                url=url,
                params=params,
                timeout=self.config["timeout"]
            )
            
            if response.status_code == 200:
                logger.info(f"âœ… Collected from fallback AAS: {endpoint}")
                return response.json()
                
        except requests.exceptions.RequestException as e:
            logger.error(f"âŒ Fallback AAS also failed: {e}")
            
        return None
    
    def collect_from_snapshot(self, timepoint: str, data_path: str) -> Optional[Any]:
        """ìŠ¤ëƒ…ìƒ· ì €ì¥ì†Œì—ì„œ ë°ì´í„° ìˆ˜ì§‘"""
        # ìŠ¤ëƒ…ìƒ· íŒŒì¼ ì°¾ê¸°
        snapshot_files = [
            f for f in os.listdir(self.snapshot_dir)
            if f.startswith(f"snapshot_{timepoint}_") and f.endswith(".json")
        ]
        
        if not snapshot_files:
            logger.warning(f"âš ï¸ No snapshot found for {timepoint}")
            return None
            
        snapshot_file = os.path.join(self.snapshot_dir, snapshot_files[0])
        
        try:
            with open(snapshot_file, 'r', encoding='utf-8') as f:
                snapshot_data = json.load(f)
                
            # ë°ì´í„° ê²½ë¡œ íƒìƒ‰
            if not data_path:
                return snapshot_data
                
            result = snapshot_data
            for key in data_path.split('.'):
                if key and key in result:
                    result = result[key]
                elif not key:
                    continue
                else:
                    logger.warning(f"âš ï¸ Path {data_path} not found in snapshot")
                    return None
                    
            logger.info(f"âœ… Collected from snapshot: {timepoint}/{data_path}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Failed to read snapshot: {e}")
            return None
    
    def collect_machines_with_cooling(self) -> List[Dict[str, Any]]:
        """ëƒ‰ê° ê¸°ëŠ¥ì´ ìˆëŠ” ê¸°ê³„ ìˆ˜ì§‘"""
        # AAS API ì‹œë„
        endpoint = "/api/machines/cooling-required"
        machines = self.collect_from_aas(endpoint)
        
        if machines:
            return machines
            
        # Fallback to snapshot
        logger.info("ğŸ“‚ Falling back to snapshot data for machines")
        snapshot_data = self.collect_from_snapshot("T2", "machines")
        
        if snapshot_data:
            # ëƒ‰ê° í•„ìš”í•œ ê¸°ê³„ë§Œ í•„í„°ë§
            cooling_machines = []
            for machine_id, machine_data in snapshot_data.items():
                if machine_data.get("cooling_required", False):
                    cooling_machines.append(machine_data)
            return cooling_machines
            
        return []
    
    def collect_job_history(self, date: str, timepoint: str = "T4") -> List[Dict[str, Any]]:
        """ì‘ì—… ì´ë ¥ ìˆ˜ì§‘"""
        # ìŠ¤ëƒ…ìƒ·ì—ì„œ ìˆ˜ì§‘ (T4: ì‹¤íŒ¨ ì‹œì )
        jobs = self.collect_from_snapshot(timepoint, "jobs")
        
        if not jobs:
            # AAS API fallback
            endpoint = f"/api/jobs/history"
            params = {"date": date}
            jobs = self.collect_from_aas(endpoint, params=params)
            
        return jobs or []
    
    def collect_sensor_data(self, machine_id: str, timepoint: str) -> Optional[Dict[str, Any]]:
        """ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘"""
        # ìŠ¤ëƒ…ìƒ·ì—ì„œ ìˆ˜ì§‘
        sensor_data = self.collect_from_snapshot(timepoint, f"sensor_data")
        
        if sensor_data and machine_id in sensor_data:
            return sensor_data[machine_id]
            
        # AAS API fallback
        endpoint = f"/shells/Machine-{machine_id}/submodels/OperationalData/timeseries"
        return self.collect_from_aas(endpoint)
    
    def collect_product_info(self, product_id: str) -> Optional[Dict[str, Any]]:
        """ì œí’ˆ ì •ë³´ ìˆ˜ì§‘"""
        # AAS API ì‹œë„
        endpoint = f"/shells/Product-{product_id}"
        product = self.collect_from_aas(endpoint)
        
        if product:
            return product
            
        # ìŠ¤ëƒ…ìƒ· fallback
        products = self.collect_from_snapshot("T1", "products")
        if products and product_id in products:
            return products[product_id]
            
        return None
    
    def collect_machine_schedule(self, timepoint: str = "T2") -> Dict[str, Any]:
        """ê¸°ê³„ ìŠ¤ì¼€ì¤„ ìˆ˜ì§‘"""
        machines = self.collect_from_snapshot(timepoint, "machines")
        
        if not machines:
            # AAS API fallback
            endpoint = "/api/machines/schedule"
            machines = self.collect_from_aas(endpoint)
            
        return machines or {}
    
    def filter_failed_jobs(self, jobs: List[Dict[str, Any]], 
                          cooling_products: List[str],
                          cooling_machines: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì‹¤íŒ¨í•œ ì‘ì—… í•„í„°ë§"""
        failed_jobs = []
        
        # cooling_machinesì—ì„œ machine_id ì¶”ì¶œ
        cooling_machine_ids = []
        if cooling_machines:
            if isinstance(cooling_machines[0], dict):
                cooling_machine_ids = [m.get("machine_id") for m in cooling_machines]
            else:
                cooling_machine_ids = cooling_machines
        
        logger.info(f"  Products requiring cooling: {cooling_products}")
        logger.info(f"  Machines with cooling: {cooling_machine_ids}")
        logger.info(f"  Total jobs to filter: {len(jobs) if jobs else 0}")
        
        if jobs:
            for job in jobs:
                if (job.get("status") == "FAILED" and
                    job.get("product_id") in cooling_products and
                    job.get("machine_id") in cooling_machine_ids):
                    
                    failed_jobs.append(job)
                    logger.info(f"    Found failed job: {job.get('job_id')}")
                
        logger.info(f"ğŸ” Filtered {len(failed_jobs)} failed jobs with cooling")
        return failed_jobs


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸
    collector = DataCollector()
    
    # ëƒ‰ê° ê¸°ê³„ ìˆ˜ì§‘
    print("\nğŸ­ Collecting cooling machines:")
    machines = collector.collect_machines_with_cooling()
    print(f"  Found {len(machines)} machines with cooling")
    
    # ì‘ì—… ì´ë ¥ ìˆ˜ì§‘
    print("\nğŸ“‹ Collecting job history:")
    jobs = collector.collect_job_history("2025-07-17")
    print(f"  Found {len(jobs)} jobs")
    
    # ì„¼ì„œ ë°ì´í„° ìˆ˜ì§‘
    print("\nğŸ“Š Collecting sensor data:")
    sensor = collector.collect_sensor_data("CNC001", "T4")
    if sensor:
        print(f"  Temperature: {sensor['summary']['avg_temperature']}Â°C")
        print(f"  Anomaly score: {sensor['summary']['anomaly_score']}")